{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training a Perceptron to perform inclusive disjunction using plain Swift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Christopher Boone](https://github.com/cboone)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/cboone/swift-neural-intuition/blob/master/1-perceptron-inclusive-disjunction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Following [Wikipedia's summary of the Perceptron learning algorithm](https://en.m.wikipedia.org/wiki/Perceptron#Learning_algorithm). Using Arrays to represent vectors and Doubles for all numbers, for simplicity._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network takes features as input vector $\\mathbf{x}_j$, a vector of weights (one per feature) as $\\mathbf{w}$, and an activation function $\\phi$, where $x_{j,i}, w_{i}, \\hat{y}_j \\in \\{0, 1\\}$ and $x_{j,0} = 1$:\n",
    "\n",
    "$$\\hat{y}_j = \\phi(\\mathbf{w} \\cdot \\mathbf{x}_j)$$\n",
    "\n",
    "Training the Perceptron requires: \n",
    "- a learning rate $r \\in [0, 1]$\n",
    "- a training set of sampled data $D = \\{(\\mathbf{x}_1, d_1), \\dots, (\\mathbf{x}_m, d_m)\\}$, where $\\mathbf{x}_j$ is the $n$-dimensional input vector, $d_j$ is the sampled (expected) output, and $m$ is the number of samples\n",
    "- an initial set of weights\n",
    "- an error threshold $\\gamma \\in [0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product of two vectors is defined by $\\mathbf{a} \\cdot \\mathbf{b} = \\sum _{i=1}^{n} a_{i} b_{i}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:52:46.763021Z",
     "iopub.status.busy": "2020-05-27T23:52:46.761952Z",
     "iopub.status.idle": "2020-05-27T23:52:54.755975Z",
     "shell.execute_reply": "2020-05-27T23:52:54.753864Z",
     "shell.execute_reply.started": "2020-05-27T23:52:46.762960Z"
    }
   },
   "outputs": [],
   "source": [
    "func dotProduct(_ a: [Double], _ b: [Double]) -> Double {\n",
    "    zip(a, b).map(*).reduce(0, +)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function is the Heaviside or unit step function, which can be defined by $H(x) = \\frac{x + \\left|x\\right|}{2x}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:52:54.759606Z",
     "iopub.status.busy": "2020-05-27T23:52:54.757961Z",
     "iopub.status.idle": "2020-05-27T23:52:55.611582Z",
     "shell.execute_reply": "2020-05-27T23:52:55.610523Z",
     "shell.execute_reply.started": "2020-05-27T23:52:54.759400Z"
    }
   },
   "outputs": [],
   "source": [
    "func unitStep(_ x: Double) -> Double {\n",
    "    (x > 0) ? 1 : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted output of the Perceptron can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:52:55.614786Z",
     "iopub.status.busy": "2020-05-27T23:52:55.613991Z",
     "iopub.status.idle": "2020-05-27T23:52:55.862783Z",
     "shell.execute_reply": "2020-05-27T23:52:55.861670Z",
     "shell.execute_reply.started": "2020-05-27T23:52:55.614737Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictedOutput(_ inputs: [Double], weights: [Double], activation: (Double) -> (Double)) -> Double {\n",
    "    activation(dotProduct(weights, inputs))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, given an array of input values, by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:52:55.865575Z",
     "iopub.status.busy": "2020-05-27T23:52:55.864873Z",
     "iopub.status.idle": "2020-05-27T23:52:56.481480Z",
     "shell.execute_reply": "2020-05-27T23:52:56.480526Z",
     "shell.execute_reply.started": "2020-05-27T23:52:55.865533Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictedOutputs(_ inputs: [[Double]], weights: [Double], activation: (Double) -> (Double)) -> [Double] {\n",
    "    inputs.map { predictedOutput($0, weights: weights, activation: activation) }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Perceptron's error function (or cost function, objective function, loss function) is defined by $E(\\mathbf{x}_j) = y_j - \\hat{y}_j$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:52:56.483659Z",
     "iopub.status.busy": "2020-05-27T23:52:56.482990Z",
     "iopub.status.idle": "2020-05-27T23:52:56.686591Z",
     "shell.execute_reply": "2020-05-27T23:52:56.685336Z",
     "shell.execute_reply.started": "2020-05-27T23:52:56.483618Z"
    }
   },
   "outputs": [],
   "source": [
    "func error(prediction: Double, sample: Double) -> Double {\n",
    "    sample - prediction\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean error is given by $\\frac{1}{m} \\sum_{j=1}^{m} \\lvert y_j - \\hat{y}_j \\rvert$, where $m$ is the number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:52:56.688946Z",
     "iopub.status.busy": "2020-05-27T23:52:56.688313Z",
     "iopub.status.idle": "2020-05-27T23:52:57.714968Z",
     "shell.execute_reply": "2020-05-27T23:52:57.714296Z",
     "shell.execute_reply.started": "2020-05-27T23:52:56.688907Z"
    }
   },
   "outputs": [],
   "source": [
    "func meanError(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let summedError = zip(samples, predictions).map(error).map(abs).reduce(0, +)\n",
    "    return (1 / Double(samples.count)) * summedError\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy (percentage correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:52:57.717653Z",
     "iopub.status.busy": "2020-05-27T23:52:57.716926Z",
     "iopub.status.idle": "2020-05-27T23:52:59.451676Z",
     "shell.execute_reply": "2020-05-27T23:52:59.450425Z",
     "shell.execute_reply.started": "2020-05-27T23:52:57.717614Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionAccuracy(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let checkedPredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        checked.append(outputs.0 == outputs.1 ? 1 : 0)\n",
    "    }\n",
    "    let correct = checkedPredictions.reduce(0, +)\n",
    "    return correct / Double(predictions.count)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of true positive predictions can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:52:59.479693Z",
     "iopub.status.busy": "2020-05-27T23:52:59.456913Z",
     "iopub.status.idle": "2020-05-27T23:53:00.143463Z",
     "shell.execute_reply": "2020-05-27T23:53:00.142718Z",
     "shell.execute_reply.started": "2020-05-27T23:52:59.460376Z"
    }
   },
   "outputs": [],
   "source": [
    "func truePositivePredictions(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositivePredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        outputs == (1, 1) ? checked.append(1) : checked.append(0)\n",
    "    }\n",
    "    return truePositivePredictions.reduce(0, +)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision (proportion of positive identifications that were actually correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:53:00.145962Z",
     "iopub.status.busy": "2020-05-27T23:53:00.144981Z",
     "iopub.status.idle": "2020-05-27T23:53:01.066740Z",
     "shell.execute_reply": "2020-05-27T23:53:01.065828Z",
     "shell.execute_reply.started": "2020-05-27T23:53:00.145914Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionPrecision(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositives = truePositivePredictions(predictions: predictions, samples: samples)\n",
    "    let allPositives = predictions.reduce(0, +)\n",
    "    return (allPositives > 0) ? (truePositives / allPositives) : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall (proportion of true positives that were actually correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:53:01.068949Z",
     "iopub.status.busy": "2020-05-27T23:53:01.068312Z",
     "iopub.status.idle": "2020-05-27T23:53:01.672482Z",
     "shell.execute_reply": "2020-05-27T23:53:01.671642Z",
     "shell.execute_reply.started": "2020-05-27T23:53:01.068906Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionRecall(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositives = truePositivePredictions(predictions: predictions, samples: samples)\n",
    "    let actualPositivePredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        switch outputs {\n",
    "        case (1, 1), (0, 1):\n",
    "            checked.append(1)\n",
    "        default:\n",
    "            checked.append(0)\n",
    "        }\n",
    "    }\n",
    "    let actualPositives = actualPositivePredictions.reduce(0, +)\n",
    "    return truePositives / actualPositives\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F₁ measure (harmonic mean of precision and recall) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:53:01.674657Z",
     "iopub.status.busy": "2020-05-27T23:53:01.673956Z",
     "iopub.status.idle": "2020-05-27T23:53:01.865842Z",
     "shell.execute_reply": "2020-05-27T23:53:01.864524Z",
     "shell.execute_reply.started": "2020-05-27T23:53:01.674614Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionF1(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let precision = predictionPrecision(predictions: predictions, samples: samples)\n",
    "    let recall = predictionRecall(predictions: predictions, samples: samples)\n",
    "    return 2 / ((1 / recall) + (1 / precision))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is the truth table for $A \\lor B$, structured as an array of tuples $[(\\mathbf{x}_j, d_j)] = [((\\mathbf{x}_{j, 1}, \\mathbf{x}_{j, 2}, \\mathbf{x}_{j, 3}), d_j)]$ where:\n",
    "\n",
    "- $\\mathbf{x}_j$ is the input\n",
    "- $\\mathbf{x}_{j, 0} = 1$ (to act as a bias value, in concert with $w_0$)\n",
    "- $d_j$ is the correct, sampled output value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:53:01.868010Z",
     "iopub.status.busy": "2020-05-27T23:53:01.867536Z",
     "iopub.status.idle": "2020-05-27T23:53:02.582527Z",
     "shell.execute_reply": "2020-05-27T23:53:02.578786Z",
     "shell.execute_reply.started": "2020-05-27T23:53:01.867979Z"
    }
   },
   "outputs": [],
   "source": [
    "let orTrainingSet: [([Double], Double)] = [\n",
    "    ([1, 0, 0], 0),\n",
    "    ([1, 0, 1], 1),\n",
    "    ([1, 1, 0], 1),\n",
    "    ([1, 1, 1], 1)\n",
    "]\n",
    "let orTrainingSetInputs: [[Double]] = orTrainingSet.map { $0.0 }\n",
    "let orTrainingSetOutputs: [Double] = orTrainingSet.map { $0.1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an untrained Perceptron with an initial set of weights $\\mathbf{w} = (0, 0, 0)$, calculate the predicted outputs for the training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:53:02.586697Z",
     "iopub.status.busy": "2020-05-27T23:53:02.584110Z",
     "iopub.status.idle": "2020-05-27T23:53:03.050976Z",
     "shell.execute_reply": "2020-05-27T23:53:03.047215Z",
     "shell.execute_reply.started": "2020-05-27T23:53:02.586632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ 4 elements\n",
       "  - 0 : 0.0\n",
       "  - 1 : 0.0\n",
       "  - 2 : 0.0\n",
       "  - 3 : 0.0\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedOutputs(orTrainingSetInputs, weights: [0, 0, 0], activation: unitStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean error for the untrained Perceptron on the training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:53:03.056330Z",
     "iopub.status.busy": "2020-05-27T23:53:03.054191Z",
     "iopub.status.idle": "2020-05-27T23:53:03.589224Z",
     "shell.execute_reply": "2020-05-27T23:53:03.588245Z",
     "shell.execute_reply.started": "2020-05-27T23:53:03.056236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanError(\n",
    "    predictions: predictedOutputs(orTrainingSetInputs, weights: [0, 0, 0], activation: unitStep),\n",
    "    samples: orTrainingSetOutputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the weights during Perceptron training, modify each weight $w_i$ by adding $r E(x_j) x_{j,i}$ to it, where $r \\in [0, 1]$ is the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:53:03.593114Z",
     "iopub.status.busy": "2020-05-27T23:53:03.592300Z",
     "iopub.status.idle": "2020-05-27T23:53:04.242442Z",
     "shell.execute_reply": "2020-05-27T23:53:04.241365Z",
     "shell.execute_reply.started": "2020-05-27T23:53:03.593064Z"
    }
   },
   "outputs": [],
   "source": [
    "func updatedWeights(_ oldWeights: [Double], error: Double, inputs: [Double], learningRate: Double) -> [Double] {\n",
    "    let weightsDelta = learningRate * error\n",
    "    let newWeights = oldWeights.enumerated().map { $1 + (weightsDelta * inputs[$0]) }\n",
    "    return newWeights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the Perceptron, calculate the predicted output $\\hat{y}_j$ based on the current weights $\\mathbf{w}$ and the activation function $\\phi$, then update the weights based on the error $E(\\mathbf{x}_j)$. Repeat until $E(\\mathbf{x}_j) < \\gamma$, where $\\gamma$ is the error threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:53:04.244699Z",
     "iopub.status.busy": "2020-05-27T23:53:04.244039Z",
     "iopub.status.idle": "2020-05-27T23:53:04.714734Z",
     "shell.execute_reply": "2020-05-27T23:53:04.713912Z",
     "shell.execute_reply.started": "2020-05-27T23:53:04.244667Z"
    }
   },
   "outputs": [],
   "source": [
    "func _printTrainingSummary(_ iterations: Int, _ epochs: Int, _ currentWeights: [Double], _ predictions: [Double], _ averageError: Double, _ accuracy: Double, _ precision: Double, _ recall: Double, _ f1: Double) {\n",
    "    print(\"Iterations:\", iterations)\n",
    "    print(\"Epochs:\", epochs)\n",
    "    print(\"Current weights:\", currentWeights)\n",
    "    print(\"Predicted outputs:\", predictions)\n",
    "    print(\"Mean error:\", averageError)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "    print(\"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:53:04.716998Z",
     "iopub.status.busy": "2020-05-27T23:53:04.716372Z",
     "iopub.status.idle": "2020-05-27T23:53:06.630296Z",
     "shell.execute_reply": "2020-05-27T23:53:06.629479Z",
     "shell.execute_reply.started": "2020-05-27T23:53:04.716958Z"
    }
   },
   "outputs": [],
   "source": [
    "func trainWeights(\n",
    "    startingFrom startingWeights: [Double],\n",
    "    samples: [([Double], Double)],\n",
    "    learningRate: Double = 0.1,\n",
    "    errorThreshold: Double = 0.25,\n",
    "    maximumIterationCount: Int = Int(1e4),\n",
    "    activation: (Double) -> (Double)\n",
    ") -> [Double]\n",
    "{\n",
    "    let sampledInputs = samples.map { $0.0 }\n",
    "    let sampledOutputs = samples.map { $0.1 }\n",
    "    let shuffledSamples = samples.shuffled()\n",
    "    let sampleCount = samples.count\n",
    "    let printMeanErrorIterationCount = maximumIterationCount / 10\n",
    "    var currentWeights = startingWeights\n",
    "    var predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "    var averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "    var accuracy = predictionAccuracy(predictions: predictions, samples: sampledOutputs)\n",
    "    var precision = predictionPrecision(predictions: predictions, samples: sampledOutputs)\n",
    "    var recall = predictionRecall(predictions: predictions, samples: sampledOutputs)\n",
    "    var f1 = predictionF1(predictions: predictions, samples: sampledOutputs)\n",
    "    var iterations = 0\n",
    "\n",
    "    while averageError >= errorThreshold {\n",
    "        if iterations >= maximumIterationCount { break }\n",
    "        if iterations % printMeanErrorIterationCount == 0 {\n",
    "            _printTrainingSummary(iterations, (iterations % sampleCount), currentWeights, predictions, averageError, accuracy, precision, recall, f1)\n",
    "        }\n",
    "        iterations += 1\n",
    "\n",
    "        let (currentInputs, currentOutput) = shuffledSamples[iterations % sampleCount]\n",
    "        let predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "        averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "        let prediction = predictedOutput(currentInputs, weights: currentWeights, activation: activation)\n",
    "        let currentError = error(prediction: prediction, sample: currentOutput)\n",
    "        currentWeights = updatedWeights(currentWeights, error: currentError, inputs: currentInputs, learningRate: learningRate)\n",
    "    }\n",
    "\n",
    "    predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "    averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "    accuracy = predictionAccuracy(predictions: predictions, samples: sampledOutputs)\n",
    "    precision = predictionPrecision(predictions: predictions, samples: sampledOutputs)\n",
    "    recall = predictionRecall(predictions: predictions, samples: sampledOutputs)\n",
    "    f1 = predictionF1(predictions: predictions, samples: sampledOutputs)\n",
    "\n",
    "    _printTrainingSummary(iterations, iterations % sampleCount, currentWeights, predictions, averageError, accuracy, precision, recall, f1)\n",
    "\n",
    "    return currentWeights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Perceptron to perform inclusive disjunction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:53:06.631961Z",
     "iopub.status.busy": "2020-05-27T23:53:06.631518Z",
     "iopub.status.idle": "2020-05-27T23:53:07.200334Z",
     "shell.execute_reply": "2020-05-27T23:53:07.198471Z",
     "shell.execute_reply.started": "2020-05-27T23:53:06.631931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0\n",
      "Epochs: 0\n",
      "Current weights: [0.0, 0.0, 0.0]\n",
      "Predicted outputs: [0.0, 0.0, 0.0, 0.0]\n",
      "Mean error: 0.75\n",
      "Accuracy: 0.25\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "\n",
      "Iterations: 6\n",
      "Epochs: 2\n",
      "Current weights: [0.0, 0.1, 0.1]\n",
      "Predicted outputs: [0.0, 1.0, 1.0, 1.0]\n",
      "Mean error: 0.0\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1: 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "▿ 3 elements\n",
       "  - 0 : 0.0\n",
       "  - 1 : 0.1\n",
       "  - 2 : 0.1\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWeights(\n",
    "    startingFrom: [0, 0, 0],\n",
    "    samples: orTrainingSet,\n",
    "    learningRate: 0.1,\n",
    "    errorThreshold: 0.25,\n",
    "    activation: unitStep\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  },
  "output_auto_scroll": true,
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

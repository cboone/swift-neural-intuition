{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training a Perceptron to perform inclusive disjunction using plain Swift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Christopher Boone](https://github.com/cboone)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/cboone/swift-neural-intuition/blob/master/1-perceptron-inclusive-disjunction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Following [Wikipedia's summary of the Perceptron learning algorithm](https://en.m.wikipedia.org/wiki/Perceptron#Learning_algorithm). Using Arrays to represent vectors and Doubles for all numbers, for simplicity._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network takes features as input vector $\\mathbf{x}_j$, a vector of weights (one per feature) as $\\mathbf{w}$, and an activation function $\\phi$, where $x_{j,i}, w_{i}, \\hat{y}_j \\in \\{0, 1\\}$ and $x_{j,0} = 1$:\n",
    "\n",
    "$$\\hat{y}_j = \\phi(\\mathbf{w} \\cdot \\mathbf{x}_j)$$\n",
    "\n",
    "Training the Perceptron requires: \n",
    "- a learning rate $r \\in [0, 1]$\n",
    "- a training set of sampled data $D = \\{(\\mathbf{x}_1, d_1), \\dots, (\\mathbf{x}_m, d_m)\\}$, where $\\mathbf{x}_j$ is the $n$-dimensional input vector, $d_j$ is the sampled (expected) output, and $m$ is the number of samples\n",
    "- an initial set of weights\n",
    "- an error threshold $\\gamma \\in [0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product of two vectors is defined by $\\mathbf{a} \\cdot \\mathbf{b} = \\sum _{i=1}^{n} a_{i} b_{i}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:35.335025Z",
     "iopub.status.busy": "2020-05-26T21:55:35.333932Z",
     "iopub.status.idle": "2020-05-26T21:55:41.534494Z",
     "shell.execute_reply": "2020-05-26T21:55:41.521570Z",
     "shell.execute_reply.started": "2020-05-26T21:55:35.334911Z"
    }
   },
   "outputs": [],
   "source": [
    "func dotProduct(_ a: [Double], _ b: [Double]) -> Double {\n",
    "    zip(a, b).map(*).reduce(0, +)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function is the Heaviside or unit step function, which can be defined by $H(x) = \\frac{x + \\left|x\\right|}{2x}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:41.537583Z",
     "iopub.status.busy": "2020-05-26T21:55:41.536641Z",
     "iopub.status.idle": "2020-05-26T21:55:42.381456Z",
     "shell.execute_reply": "2020-05-26T21:55:42.380246Z",
     "shell.execute_reply.started": "2020-05-26T21:55:41.537542Z"
    }
   },
   "outputs": [],
   "source": [
    "func unitStep(_ x: Double) -> Double {\n",
    "    (x > 0) ? 1 : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted output of the Perceptron can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:42.406634Z",
     "iopub.status.busy": "2020-05-26T21:55:42.401073Z",
     "iopub.status.idle": "2020-05-26T21:55:42.624194Z",
     "shell.execute_reply": "2020-05-26T21:55:42.623157Z",
     "shell.execute_reply.started": "2020-05-26T21:55:42.406591Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictedOutput(_ inputs: [Double], weights: [Double], activation: (Double) -> (Double)) -> Double {\n",
    "    activation(dotProduct(weights, inputs))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, given an array of input values, by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:42.638085Z",
     "iopub.status.busy": "2020-05-26T21:55:42.636597Z",
     "iopub.status.idle": "2020-05-26T21:55:43.254676Z",
     "shell.execute_reply": "2020-05-26T21:55:43.252211Z",
     "shell.execute_reply.started": "2020-05-26T21:55:42.637853Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictedOutputs(_ inputs: [[Double]], weights: [Double], activation: (Double) -> (Double)) -> [Double] {\n",
    "    inputs.map { predictedOutput($0, weights: weights, activation: activation) }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Perceptron's error function (or cost function, objective function, loss function) is defined by $E(\\mathbf{x}_j) = y_j - \\hat{y}_j$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:43.256745Z",
     "iopub.status.busy": "2020-05-26T21:55:43.255852Z",
     "iopub.status.idle": "2020-05-26T21:55:43.476532Z",
     "shell.execute_reply": "2020-05-26T21:55:43.475580Z",
     "shell.execute_reply.started": "2020-05-26T21:55:43.256188Z"
    }
   },
   "outputs": [],
   "source": [
    "func error(prediction: Double, sample: Double) -> Double {\n",
    "    sample - prediction\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean error is given by $\\frac{1}{m} \\sum_{j=1}^{m} \\lvert y_j - \\hat{y}_j \\rvert$, where $m$ is the number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:43.477678Z",
     "iopub.status.busy": "2020-05-26T21:55:43.477497Z",
     "iopub.status.idle": "2020-05-26T21:55:44.479109Z",
     "shell.execute_reply": "2020-05-26T21:55:44.478147Z",
     "shell.execute_reply.started": "2020-05-26T21:55:43.477653Z"
    }
   },
   "outputs": [],
   "source": [
    "func meanError(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let summedError = zip(samples, predictions).map(error).map(abs).reduce(0, +)\n",
    "    return (1 / Double(samples.count)) * summedError\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy (percentage correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:44.484456Z",
     "iopub.status.busy": "2020-05-26T21:55:44.484194Z",
     "iopub.status.idle": "2020-05-26T21:55:45.822016Z",
     "shell.execute_reply": "2020-05-26T21:55:45.820003Z",
     "shell.execute_reply.started": "2020-05-26T21:55:44.484430Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionAccuracy(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let checkedPredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        checked.append(outputs.0 == outputs.1 ? 1 : 0)\n",
    "    }\n",
    "    let correct = checkedPredictions.reduce(0, +)\n",
    "    return correct / Double(predictions.count)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of true positive predictions can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:45.826504Z",
     "iopub.status.busy": "2020-05-26T21:55:45.824291Z",
     "iopub.status.idle": "2020-05-26T21:55:46.604418Z",
     "shell.execute_reply": "2020-05-26T21:55:46.603008Z",
     "shell.execute_reply.started": "2020-05-26T21:55:45.826450Z"
    }
   },
   "outputs": [],
   "source": [
    "func truePositivePredictions(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositivePredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        outputs == (1, 1) ? checked.append(1) : checked.append(0)\n",
    "    }\n",
    "    return truePositivePredictions.reduce(0, +)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision (proportion of positive identifications that were actually correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:46.609598Z",
     "iopub.status.busy": "2020-05-26T21:55:46.609248Z",
     "iopub.status.idle": "2020-05-26T21:55:47.376942Z",
     "shell.execute_reply": "2020-05-26T21:55:47.375649Z",
     "shell.execute_reply.started": "2020-05-26T21:55:46.609561Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionPrecision(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositives = truePositivePredictions(predictions: predictions, samples: samples)\n",
    "    let allPositives = predictions.reduce(0, +)\n",
    "    return (allPositives > 0) ? (truePositives / allPositives) : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall (proportion of true positives that were actually correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:47.378083Z",
     "iopub.status.busy": "2020-05-26T21:55:47.377837Z",
     "iopub.status.idle": "2020-05-26T21:55:48.061368Z",
     "shell.execute_reply": "2020-05-26T21:55:48.059052Z",
     "shell.execute_reply.started": "2020-05-26T21:55:47.378058Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionRecall(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositives = truePositivePredictions(predictions: predictions, samples: samples)\n",
    "    let actualPositivePredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        switch outputs {\n",
    "        case (1, 1), (0, 1):\n",
    "            checked.append(1)\n",
    "        default:\n",
    "            checked.append(0)\n",
    "        }\n",
    "    }\n",
    "    let actualPositives = actualPositivePredictions.reduce(0, +)\n",
    "    return truePositives / actualPositives\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F₁ measure (harmonic mean of precision and recall) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:48.071356Z",
     "iopub.status.busy": "2020-05-26T21:55:48.070682Z",
     "iopub.status.idle": "2020-05-26T21:55:48.275511Z",
     "shell.execute_reply": "2020-05-26T21:55:48.273456Z",
     "shell.execute_reply.started": "2020-05-26T21:55:48.071241Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionF1(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let precision = predictionPrecision(predictions: predictions, samples: samples)\n",
    "    let recall = predictionRecall(predictions: predictions, samples: samples)\n",
    "    return 2 / ((1 / recall) + (1 / precision))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is the truth table for $A \\lor B$, structured as an array of tuples $[(\\mathbf{x}_j, d_j)] = [((\\mathbf{x}_{j, 1}, \\mathbf{x}_{j, 2}, \\mathbf{x}_{j, 3}), d_j)]$ where:\n",
    "\n",
    "- $\\mathbf{x}_j$ is the input\n",
    "- $\\mathbf{x}_{j, 0} = 1$ (to act as a bias value, in concert with $w_0$)\n",
    "- $d_j$ is the correct, sampled output value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:48.277152Z",
     "iopub.status.busy": "2020-05-26T21:55:48.276735Z",
     "iopub.status.idle": "2020-05-26T21:55:49.077165Z",
     "shell.execute_reply": "2020-05-26T21:55:49.076347Z",
     "shell.execute_reply.started": "2020-05-26T21:55:48.277109Z"
    }
   },
   "outputs": [],
   "source": [
    "let orTrainingSet: [([Double], Double)] = [\n",
    "    ([1, 0, 0], 0),\n",
    "    ([1, 0, 1], 1),\n",
    "    ([1, 1, 0], 1),\n",
    "    ([1, 1, 1], 1)\n",
    "]\n",
    "let orTrainingSetInputs: [[Double]] = orTrainingSet.map { $0.0 }\n",
    "let orTrainingSetOutputs: [Double] = orTrainingSet.map { $0.1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an untrained Perceptron with an initial set of weights $\\mathbf{w} = (0, 0, 0)$, calculate the predicted outputs for the training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:49.079334Z",
     "iopub.status.busy": "2020-05-26T21:55:49.078264Z",
     "iopub.status.idle": "2020-05-26T21:55:49.697529Z",
     "shell.execute_reply": "2020-05-26T21:55:49.695705Z",
     "shell.execute_reply.started": "2020-05-26T21:55:49.079287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ 4 elements\n",
       "  - 0 : 0.0\n",
       "  - 1 : 0.0\n",
       "  - 2 : 0.0\n",
       "  - 3 : 0.0\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedOutputs(orTrainingSetInputs, weights: [0, 0, 0], activation: unitStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean error for the untrained Perceptron on the training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:49.747265Z",
     "iopub.status.busy": "2020-05-26T21:55:49.702386Z",
     "iopub.status.idle": "2020-05-26T21:55:50.292204Z",
     "shell.execute_reply": "2020-05-26T21:55:50.286780Z",
     "shell.execute_reply.started": "2020-05-26T21:55:49.747198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanError(\n",
    "    predictions: predictedOutputs(orTrainingSetInputs, weights: [0, 0, 0], activation: unitStep), \n",
    "    samples: orTrainingSetOutputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the weights during Perceptron training, modify each weight $w_i$ by adding $r E(x_j) x_{j,i}$ to it, where $r \\in [0, 1]$ is the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T21:55:50.297567Z",
     "iopub.status.busy": "2020-05-26T21:55:50.296446Z",
     "iopub.status.idle": "2020-05-26T21:55:51.048344Z",
     "shell.execute_reply": "2020-05-26T21:55:51.047522Z",
     "shell.execute_reply.started": "2020-05-26T21:55:50.297520Z"
    }
   },
   "outputs": [],
   "source": [
    "func updatedWeights(_ oldWeights: [Double], error: Double, inputs: [Double], learningRate: Double) -> [Double] {\n",
    "    let weightsDelta = learningRate * error\n",
    "    let newWeights = oldWeights.enumerated().map { $1 + (weightsDelta * inputs[$0]) }\n",
    "    return newWeights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the Perceptron, calculate the predicted output $\\hat{y}_j$ based on the current weights $\\mathbf{w}$ and the activation function $\\phi$, then update the weights based on the error $E(\\mathbf{x}_j)$. Repeat until $E(\\mathbf{x}_j) < \\gamma$, where $\\gamma$ is the error threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T22:14:54.285091Z",
     "iopub.status.busy": "2020-05-26T22:14:54.284663Z",
     "iopub.status.idle": "2020-05-26T22:14:56.500576Z",
     "shell.execute_reply": "2020-05-26T22:14:56.499797Z",
     "shell.execute_reply.started": "2020-05-26T22:14:54.285046Z"
    }
   },
   "outputs": [],
   "source": [
    "func trainWeights(\n",
    "    startingFrom startingWeights: [Double], \n",
    "    samples: [([Double], Double)], \n",
    "    learningRate: Double,\n",
    "    errorThreshold: Double,\n",
    "    activation: (Double) -> (Double)\n",
    ") -> [Double] \n",
    "{\n",
    "    let sampledInputs = samples.map { $0.0 }\n",
    "    let sampledOutputs = samples.map { $0.1 }\n",
    "    let shuffledSamples = samples.shuffled()\n",
    "    let sampleCount = samples.count\n",
    "    var currentWeights = startingWeights\n",
    "    var predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "    var averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "    var accuracy = predictionAccuracy(predictions: predictions, samples: sampledOutputs)\n",
    "    var precision = predictionPrecision(predictions: predictions, samples: sampledOutputs)\n",
    "    var recall = predictionRecall(predictions: predictions, samples: sampledOutputs)\n",
    "    var f1 = predictionF1(predictions: predictions, samples: sampledOutputs)\n",
    "    var iterations = 0\n",
    "\n",
    "    print(\"Starting weights:\", startingWeights)\n",
    "    print(\"Predicted outputs:\", predictions)\n",
    "    print(\"Mean error:\", averageError)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "    print(\"\")\n",
    "\n",
    "    while averageError >= errorThreshold {\n",
    "        iterations += 1\n",
    "        \n",
    "        let (currentInputs, currentOutput) = shuffledSamples[iterations % sampleCount]\n",
    "        let predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "        averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "        let prediction = predictedOutput(currentInputs, weights: currentWeights, activation: activation)\n",
    "        let currentError = error(prediction: prediction, sample: currentOutput)\n",
    "        currentWeights = updatedWeights(currentWeights, error: currentError, inputs: currentInputs, learningRate: learningRate)\n",
    "    }\n",
    "\n",
    "    predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "    averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "    accuracy = predictionAccuracy(predictions: predictions, samples: sampledOutputs)\n",
    "    precision = predictionPrecision(predictions: predictions, samples: sampledOutputs)\n",
    "    recall = predictionRecall(predictions: predictions, samples: sampledOutputs)\n",
    "    f1 = predictionF1(predictions: predictions, samples: sampledOutputs)\n",
    "\n",
    "    print(\"Epochs:\", iterations / sampleCount)\n",
    "    print(\"Iterations:\", iterations)\n",
    "    print(\"Final weights:\", currentWeights)\n",
    "    print(\"Predicted outputs:\", predictions)\n",
    "    print(\"Mean error:\", averageError)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "\n",
    "    return currentWeights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Perceptron to perform inclusive disjunction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-26T22:15:31.463024Z",
     "iopub.status.busy": "2020-05-26T22:15:31.462324Z",
     "iopub.status.idle": "2020-05-26T22:15:32.122298Z",
     "shell.execute_reply": "2020-05-26T22:15:32.121120Z",
     "shell.execute_reply.started": "2020-05-26T22:15:31.462976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights: [0.0, 0.0, 0.0]\n",
      "Predicted outputs: [0.0, 0.0, 0.0, 0.0]\n",
      "Mean error: 0.75\n",
      "Accuracy: 0.25\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "\n",
      "Epochs: 1\n",
      "Iterations: 7\n",
      "Final weights: [0.0, 0.1, 0.1]\n",
      "Predicted outputs: [0.0, 1.0, 1.0, 1.0]\n",
      "Mean error: 0.0\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "▿ 3 elements\n",
       "  - 0 : 0.0\n",
       "  - 1 : 0.1\n",
       "  - 2 : 0.1\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWeights(\n",
    "    startingFrom: [0, 0, 0], \n",
    "    samples: orTrainingSet, \n",
    "    learningRate: 0.1, \n",
    "    errorThreshold: 0.25, \n",
    "    activation: unitStep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

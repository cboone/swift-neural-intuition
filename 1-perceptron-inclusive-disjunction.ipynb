{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training a Perceptron to perform inclusive disjunction using plain Swift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Christopher Boone](https://github.com/cboone)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/cboone/swift-neural-intuition/blob/master/1-perceptron-inclusive-disjunction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Following [Wikipedia's summary of the Perceptron learning algorithm](https://en.m.wikipedia.org/wiki/Perceptron#Learning_algorithm). Using Arrays to represent vectors and Doubles for all numbers, for simplicity._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network takes features as input vector $\\mathbf{x}_j$, a vector of weights (one per feature) as $\\mathbf{w}$, and an activation function $\\phi$, where $x_{j,i}, w_{i}, \\hat{y}_j \\in \\{0, 1\\}$ and $x_{j,0} = 1$:\n",
    "\n",
    "$$\\hat{y}_j = \\phi(\\mathbf{w} \\cdot \\mathbf{x}_j)$$\n",
    "\n",
    "Training the Perceptron requires: \n",
    "- a learning rate $r \\in [0, 1]$\n",
    "- a training set of sampled data $D = \\{(\\mathbf{x}_1, d_1), \\dots, (\\mathbf{x}_m, d_m)\\}$, where $\\mathbf{x}_j$ is the $n$-dimensional input vector, $d_j$ is the sampled (expected) output, and $m$ is the number of samples\n",
    "- an initial set of weights\n",
    "- an error threshold $\\gamma \\in [0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product of two vectors is defined by $\\mathbf{a} \\cdot \\mathbf{b} = \\sum _{i=1}^{n} a_{i} b_{i}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:18:57.235202Z",
     "iopub.status.busy": "2020-05-27T01:18:57.234702Z",
     "iopub.status.idle": "2020-05-27T01:19:02.770396Z",
     "shell.execute_reply": "2020-05-27T01:19:02.762547Z",
     "shell.execute_reply.started": "2020-05-27T01:18:57.235163Z"
    }
   },
   "outputs": [],
   "source": [
    "func dotProduct(_ a: [Double], _ b: [Double]) -> Double {\n",
    "    zip(a, b).map(*).reduce(0, +)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function is the Heaviside or unit step function, which can be defined by $H(x) = \\frac{x + \\left|x\\right|}{2x}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:02.776903Z",
     "iopub.status.busy": "2020-05-27T01:19:02.776392Z",
     "iopub.status.idle": "2020-05-27T01:19:03.651364Z",
     "shell.execute_reply": "2020-05-27T01:19:03.650399Z",
     "shell.execute_reply.started": "2020-05-27T01:19:02.776846Z"
    }
   },
   "outputs": [],
   "source": [
    "func unitStep(_ x: Double) -> Double {\n",
    "    (x > 0) ? 1 : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted output of the Perceptron can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:03.656355Z",
     "iopub.status.busy": "2020-05-27T01:19:03.655321Z",
     "iopub.status.idle": "2020-05-27T01:19:03.861448Z",
     "shell.execute_reply": "2020-05-27T01:19:03.860324Z",
     "shell.execute_reply.started": "2020-05-27T01:19:03.656302Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictedOutput(_ inputs: [Double], weights: [Double], activation: (Double) -> (Double)) -> Double {\n",
    "    activation(dotProduct(weights, inputs))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, given an array of input values, by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:03.865884Z",
     "iopub.status.busy": "2020-05-27T01:19:03.865274Z",
     "iopub.status.idle": "2020-05-27T01:19:04.448018Z",
     "shell.execute_reply": "2020-05-27T01:19:04.447162Z",
     "shell.execute_reply.started": "2020-05-27T01:19:03.865742Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictedOutputs(_ inputs: [[Double]], weights: [Double], activation: (Double) -> (Double)) -> [Double] {\n",
    "    inputs.map { predictedOutput($0, weights: weights, activation: activation) }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Perceptron's error function (or cost function, objective function, loss function) is defined by $E(\\mathbf{x}_j) = y_j - \\hat{y}_j$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:04.451495Z",
     "iopub.status.busy": "2020-05-27T01:19:04.450204Z",
     "iopub.status.idle": "2020-05-27T01:19:04.645076Z",
     "shell.execute_reply": "2020-05-27T01:19:04.644043Z",
     "shell.execute_reply.started": "2020-05-27T01:19:04.451441Z"
    }
   },
   "outputs": [],
   "source": [
    "func error(prediction: Double, sample: Double) -> Double {\n",
    "    sample - prediction\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean error is given by $\\frac{1}{m} \\sum_{j=1}^{m} \\lvert y_j - \\hat{y}_j \\rvert$, where $m$ is the number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:04.646471Z",
     "iopub.status.busy": "2020-05-27T01:19:04.646080Z",
     "iopub.status.idle": "2020-05-27T01:19:05.819576Z",
     "shell.execute_reply": "2020-05-27T01:19:05.817579Z",
     "shell.execute_reply.started": "2020-05-27T01:19:04.646432Z"
    }
   },
   "outputs": [],
   "source": [
    "func meanError(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let summedError = zip(samples, predictions).map(error).map(abs).reduce(0, +)\n",
    "    return (1 / Double(samples.count)) * summedError\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy (percentage correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:05.821732Z",
     "iopub.status.busy": "2020-05-27T01:19:05.821195Z",
     "iopub.status.idle": "2020-05-27T01:19:07.068343Z",
     "shell.execute_reply": "2020-05-27T01:19:07.067575Z",
     "shell.execute_reply.started": "2020-05-27T01:19:05.821705Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionAccuracy(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let checkedPredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        checked.append(outputs.0 == outputs.1 ? 1 : 0)\n",
    "    }\n",
    "    let correct = checkedPredictions.reduce(0, +)\n",
    "    return correct / Double(predictions.count)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of true positive predictions can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:07.069689Z",
     "iopub.status.busy": "2020-05-27T01:19:07.069319Z",
     "iopub.status.idle": "2020-05-27T01:19:07.793857Z",
     "shell.execute_reply": "2020-05-27T01:19:07.792909Z",
     "shell.execute_reply.started": "2020-05-27T01:19:07.069659Z"
    }
   },
   "outputs": [],
   "source": [
    "func truePositivePredictions(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositivePredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        outputs == (1, 1) ? checked.append(1) : checked.append(0)\n",
    "    }\n",
    "    return truePositivePredictions.reduce(0, +)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision (proportion of positive identifications that were actually correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:07.797668Z",
     "iopub.status.busy": "2020-05-27T01:19:07.796218Z",
     "iopub.status.idle": "2020-05-27T01:19:08.652589Z",
     "shell.execute_reply": "2020-05-27T01:19:08.650903Z",
     "shell.execute_reply.started": "2020-05-27T01:19:07.797432Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionPrecision(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositives = truePositivePredictions(predictions: predictions, samples: samples)\n",
    "    let allPositives = predictions.reduce(0, +)\n",
    "    return (allPositives > 0) ? (truePositives / allPositives) : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall (proportion of true positives that were actually correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:08.657203Z",
     "iopub.status.busy": "2020-05-27T01:19:08.655144Z",
     "iopub.status.idle": "2020-05-27T01:19:09.409985Z",
     "shell.execute_reply": "2020-05-27T01:19:09.409153Z",
     "shell.execute_reply.started": "2020-05-27T01:19:08.656248Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionRecall(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositives = truePositivePredictions(predictions: predictions, samples: samples)\n",
    "    let actualPositivePredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        switch outputs {\n",
    "        case (1, 1), (0, 1):\n",
    "            checked.append(1)\n",
    "        default:\n",
    "            checked.append(0)\n",
    "        }\n",
    "    }\n",
    "    let actualPositives = actualPositivePredictions.reduce(0, +)\n",
    "    return truePositives / actualPositives\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F₁ measure (harmonic mean of precision and recall) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:09.411503Z",
     "iopub.status.busy": "2020-05-27T01:19:09.411119Z",
     "iopub.status.idle": "2020-05-27T01:19:09.739757Z",
     "shell.execute_reply": "2020-05-27T01:19:09.738190Z",
     "shell.execute_reply.started": "2020-05-27T01:19:09.411473Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionF1(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let precision = predictionPrecision(predictions: predictions, samples: samples)\n",
    "    let recall = predictionRecall(predictions: predictions, samples: samples)\n",
    "    return 2 / ((1 / recall) + (1 / precision))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is the truth table for $A \\lor B$, structured as an array of tuples $[(\\mathbf{x}_j, d_j)] = [((\\mathbf{x}_{j, 1}, \\mathbf{x}_{j, 2}, \\mathbf{x}_{j, 3}), d_j)]$ where:\n",
    "\n",
    "- $\\mathbf{x}_j$ is the input\n",
    "- $\\mathbf{x}_{j, 0} = 1$ (to act as a bias value, in concert with $w_0$)\n",
    "- $d_j$ is the correct, sampled output value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:09.744404Z",
     "iopub.status.busy": "2020-05-27T01:19:09.743763Z",
     "iopub.status.idle": "2020-05-27T01:19:10.641536Z",
     "shell.execute_reply": "2020-05-27T01:19:10.639960Z",
     "shell.execute_reply.started": "2020-05-27T01:19:09.744366Z"
    }
   },
   "outputs": [],
   "source": [
    "let orTrainingSet: [([Double], Double)] = [\n",
    "    ([1, 0, 0], 0),\n",
    "    ([1, 0, 1], 1),\n",
    "    ([1, 1, 0], 1),\n",
    "    ([1, 1, 1], 1)\n",
    "]\n",
    "let orTrainingSetInputs: [[Double]] = orTrainingSet.map { $0.0 }\n",
    "let orTrainingSetOutputs: [Double] = orTrainingSet.map { $0.1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an untrained Perceptron with an initial set of weights $\\mathbf{w} = (0, 0, 0)$, calculate the predicted outputs for the training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:10.645340Z",
     "iopub.status.busy": "2020-05-27T01:19:10.644966Z",
     "iopub.status.idle": "2020-05-27T01:19:11.117664Z",
     "shell.execute_reply": "2020-05-27T01:19:11.116973Z",
     "shell.execute_reply.started": "2020-05-27T01:19:10.645242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ 4 elements\n",
       "  - 0 : 0.0\n",
       "  - 1 : 0.0\n",
       "  - 2 : 0.0\n",
       "  - 3 : 0.0\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedOutputs(orTrainingSetInputs, weights: [0, 0, 0], activation: unitStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean error for the untrained Perceptron on the training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:11.122960Z",
     "iopub.status.busy": "2020-05-27T01:19:11.119282Z",
     "iopub.status.idle": "2020-05-27T01:19:11.907969Z",
     "shell.execute_reply": "2020-05-27T01:19:11.906995Z",
     "shell.execute_reply.started": "2020-05-27T01:19:11.122910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanError(\n",
    "    predictions: predictedOutputs(orTrainingSetInputs, weights: [0, 0, 0], activation: unitStep),\n",
    "    samples: orTrainingSetOutputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the weights during Perceptron training, modify each weight $w_i$ by adding $r E(x_j) x_{j,i}$ to it, where $r \\in [0, 1]$ is the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:11.911068Z",
     "iopub.status.busy": "2020-05-27T01:19:11.909412Z",
     "iopub.status.idle": "2020-05-27T01:19:13.027463Z",
     "shell.execute_reply": "2020-05-27T01:19:13.026315Z",
     "shell.execute_reply.started": "2020-05-27T01:19:11.910524Z"
    }
   },
   "outputs": [],
   "source": [
    "func updatedWeights(_ oldWeights: [Double], error: Double, inputs: [Double], learningRate: Double) -> [Double] {\n",
    "    let weightsDelta = learningRate * error\n",
    "    let newWeights = oldWeights.enumerated().map { $1 + (weightsDelta * inputs[$0]) }\n",
    "    return newWeights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the Perceptron, calculate the predicted output $\\hat{y}_j$ based on the current weights $\\mathbf{w}$ and the activation function $\\phi$, then update the weights based on the error $E(\\mathbf{x}_j)$. Repeat until $E(\\mathbf{x}_j) < \\gamma$, where $\\gamma$ is the error threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:13.030081Z",
     "iopub.status.busy": "2020-05-27T01:19:13.029462Z",
     "iopub.status.idle": "2020-05-27T01:19:16.100064Z",
     "shell.execute_reply": "2020-05-27T01:19:16.098264Z",
     "shell.execute_reply.started": "2020-05-27T01:19:13.030046Z"
    }
   },
   "outputs": [],
   "source": [
    "func trainWeights(\n",
    "    startingFrom startingWeights: [Double],\n",
    "    samples: [([Double], Double)],\n",
    "    learningRate: Double,\n",
    "    errorThreshold: Double,\n",
    "    activation: (Double) -> (Double)\n",
    ") -> [Double]\n",
    "{\n",
    "    let sampledInputs = samples.map { $0.0 }\n",
    "    let sampledOutputs = samples.map { $0.1 }\n",
    "    let shuffledSamples = samples.shuffled()\n",
    "    let sampleCount = samples.count\n",
    "    var currentWeights = startingWeights\n",
    "    var predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "    var averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "    var accuracy = predictionAccuracy(predictions: predictions, samples: sampledOutputs)\n",
    "    var precision = predictionPrecision(predictions: predictions, samples: sampledOutputs)\n",
    "    var recall = predictionRecall(predictions: predictions, samples: sampledOutputs)\n",
    "    var f1 = predictionF1(predictions: predictions, samples: sampledOutputs)\n",
    "    var iterations = 0\n",
    "\n",
    "    print(\"Starting weights:\", startingWeights)\n",
    "    print(\"Predicted outputs:\", predictions)\n",
    "    print(\"Mean error:\", averageError)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "    print(\"\")\n",
    "\n",
    "    while averageError >= errorThreshold {\n",
    "        iterations += 1\n",
    "\n",
    "        let (currentInputs, currentOutput) = shuffledSamples[iterations % sampleCount]\n",
    "        let predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "        averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "        let prediction = predictedOutput(currentInputs, weights: currentWeights, activation: activation)\n",
    "        let currentError = error(prediction: prediction, sample: currentOutput)\n",
    "        currentWeights = updatedWeights(currentWeights, error: currentError, inputs: currentInputs, learningRate: learningRate)\n",
    "    }\n",
    "\n",
    "    predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "    averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "    accuracy = predictionAccuracy(predictions: predictions, samples: sampledOutputs)\n",
    "    precision = predictionPrecision(predictions: predictions, samples: sampledOutputs)\n",
    "    recall = predictionRecall(predictions: predictions, samples: sampledOutputs)\n",
    "    f1 = predictionF1(predictions: predictions, samples: sampledOutputs)\n",
    "\n",
    "    print(\"Epochs:\", iterations / sampleCount)\n",
    "    print(\"Iterations:\", iterations)\n",
    "    print(\"Final weights:\", currentWeights)\n",
    "    print(\"Predicted outputs:\", predictions)\n",
    "    print(\"Mean error:\", averageError)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "\n",
    "    return currentWeights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Perceptron to perform inclusive disjunction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T01:19:16.106033Z",
     "iopub.status.busy": "2020-05-27T01:19:16.104011Z",
     "iopub.status.idle": "2020-05-27T01:19:16.934063Z",
     "shell.execute_reply": "2020-05-27T01:19:16.932141Z",
     "shell.execute_reply.started": "2020-05-27T01:19:16.105983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights: [0.0, 0.0, 0.0]\n",
      "Predicted outputs: [0.0, 0.0, 0.0, 0.0]\n",
      "Mean error: 0.75\n",
      "Accuracy: 0.25\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "\n",
      "Epochs: 2\n",
      "Iterations: 10\n",
      "Final weights: [0.0, 0.1, 0.1]\n",
      "Predicted outputs: [0.0, 1.0, 1.0, 1.0]\n",
      "Mean error: 0.0\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "▿ 3 elements\n",
       "  - 0 : 0.0\n",
       "  - 1 : 0.1\n",
       "  - 2 : 0.1\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWeights(\n",
    "    startingFrom: [0, 0, 0],\n",
    "    samples: orTrainingSet,\n",
    "    learningRate: 0.1,\n",
    "    errorThreshold: 0.25,\n",
    "    activation: unitStep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  },
  "output_auto_scroll": true,
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

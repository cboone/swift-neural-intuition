{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training a Perceptron to perform inclusive disjunction using plain Swift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Christopher Boone](https://github.com/cboone)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/cboone/swift-neural-intuition/blob/master/1-perceptron-inclusive-disjunction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Following [Wikipedia's summary of the Perceptron learning algorithm](https://en.m.wikipedia.org/wiki/Perceptron#Learning_algorithm). Using Arrays to represent vectors and Doubles for all numbers, for simplicity._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network takes features as input vector $\\mathbf{x}_j$, a vector of weights (one per feature) as $\\mathbf{w}$, and an activation function $\\phi$, where $x_{j,i}, w_{i}, \\hat{y}_j \\in \\{0, 1\\}$ and $x_{j,0} = 1$:\n",
    "\n",
    "$$\\hat{y}_j = \\phi(\\mathbf{w} \\cdot \\mathbf{x}_j)$$\n",
    "\n",
    "Training the Perceptron requires: \n",
    "- a learning rate $r \\in [0, 1]$\n",
    "- a training set of sampled data $D = \\{(\\mathbf{x}_1, d_1), \\dots, (\\mathbf{x}_m, d_m)\\}$, where $\\mathbf{x}_j$ is the $n$-dimensional input vector, $d_j$ is the sampled (expected) output, and $m$ is the number of samples\n",
    "- an initial set of weights\n",
    "- an error threshold $\\gamma \\in [0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product of two vectors is defined by $\\mathbf{a} \\cdot \\mathbf{b} = \\sum _{i=1}^{n} a_{i} b_{i}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:22.078073Z",
     "iopub.status.busy": "2020-05-27T23:33:22.076198Z",
     "iopub.status.idle": "2020-05-27T23:33:27.733168Z",
     "shell.execute_reply": "2020-05-27T23:33:27.732032Z",
     "shell.execute_reply.started": "2020-05-27T23:33:22.077994Z"
    }
   },
   "outputs": [],
   "source": [
    "func dotProduct(_ a: [Double], _ b: [Double]) -> Double {\n",
    "    zip(a, b).map(*).reduce(0, +)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function is the Heaviside or unit step function, which can be defined by $H(x) = \\frac{x + \\left|x\\right|}{2x}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:27.757356Z",
     "iopub.status.busy": "2020-05-27T23:33:27.749806Z",
     "iopub.status.idle": "2020-05-27T23:33:28.637740Z",
     "shell.execute_reply": "2020-05-27T23:33:28.636455Z",
     "shell.execute_reply.started": "2020-05-27T23:33:27.757243Z"
    }
   },
   "outputs": [],
   "source": [
    "func unitStep(_ x: Double) -> Double {\n",
    "    (x > 0) ? 1 : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted output of the Perceptron can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:28.645251Z",
     "iopub.status.busy": "2020-05-27T23:33:28.644771Z",
     "iopub.status.idle": "2020-05-27T23:33:29.018794Z",
     "shell.execute_reply": "2020-05-27T23:33:29.017248Z",
     "shell.execute_reply.started": "2020-05-27T23:33:28.645212Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictedOutput(_ inputs: [Double], weights: [Double], activation: (Double) -> (Double)) -> Double {\n",
    "    activation(dotProduct(weights, inputs))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, given an array of input values, by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:29.067686Z",
     "iopub.status.busy": "2020-05-27T23:33:29.066421Z",
     "iopub.status.idle": "2020-05-27T23:33:30.505892Z",
     "shell.execute_reply": "2020-05-27T23:33:30.505215Z",
     "shell.execute_reply.started": "2020-05-27T23:33:29.067563Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictedOutputs(_ inputs: [[Double]], weights: [Double], activation: (Double) -> (Double)) -> [Double] {\n",
    "    inputs.map { predictedOutput($0, weights: weights, activation: activation) }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Perceptron's error function (or cost function, objective function, loss function) is defined by $E(\\mathbf{x}_j) = y_j - \\hat{y}_j$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:30.537661Z",
     "iopub.status.busy": "2020-05-27T23:33:30.513013Z",
     "iopub.status.idle": "2020-05-27T23:33:30.746000Z",
     "shell.execute_reply": "2020-05-27T23:33:30.744803Z",
     "shell.execute_reply.started": "2020-05-27T23:33:30.537608Z"
    }
   },
   "outputs": [],
   "source": [
    "func error(prediction: Double, sample: Double) -> Double {\n",
    "    sample - prediction\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean error is given by $\\frac{1}{m} \\sum_{j=1}^{m} \\lvert y_j - \\hat{y}_j \\rvert$, where $m$ is the number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:30.747639Z",
     "iopub.status.busy": "2020-05-27T23:33:30.747377Z",
     "iopub.status.idle": "2020-05-27T23:33:31.624779Z",
     "shell.execute_reply": "2020-05-27T23:33:31.623430Z",
     "shell.execute_reply.started": "2020-05-27T23:33:30.747604Z"
    }
   },
   "outputs": [],
   "source": [
    "func meanError(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let summedError = zip(samples, predictions).map(error).map(abs).reduce(0, +)\n",
    "    return (1 / Double(samples.count)) * summedError\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy (percentage correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:31.626427Z",
     "iopub.status.busy": "2020-05-27T23:33:31.625923Z",
     "iopub.status.idle": "2020-05-27T23:33:32.734256Z",
     "shell.execute_reply": "2020-05-27T23:33:32.733284Z",
     "shell.execute_reply.started": "2020-05-27T23:33:31.626381Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionAccuracy(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let checkedPredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        checked.append(outputs.0 == outputs.1 ? 1 : 0)\n",
    "    }\n",
    "    let correct = checkedPredictions.reduce(0, +)\n",
    "    return correct / Double(predictions.count)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of true positive predictions can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:32.736436Z",
     "iopub.status.busy": "2020-05-27T23:33:32.735958Z",
     "iopub.status.idle": "2020-05-27T23:33:33.764792Z",
     "shell.execute_reply": "2020-05-27T23:33:33.761528Z",
     "shell.execute_reply.started": "2020-05-27T23:33:32.736403Z"
    }
   },
   "outputs": [],
   "source": [
    "func truePositivePredictions(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositivePredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        outputs == (1, 1) ? checked.append(1) : checked.append(0)\n",
    "    }\n",
    "    return truePositivePredictions.reduce(0, +)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision (proportion of positive identifications that were actually correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:33.772125Z",
     "iopub.status.busy": "2020-05-27T23:33:33.771797Z",
     "iopub.status.idle": "2020-05-27T23:33:34.656910Z",
     "shell.execute_reply": "2020-05-27T23:33:34.652457Z",
     "shell.execute_reply.started": "2020-05-27T23:33:33.772096Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionPrecision(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositives = truePositivePredictions(predictions: predictions, samples: samples)\n",
    "    let allPositives = predictions.reduce(0, +)\n",
    "    return (allPositives > 0) ? (truePositives / allPositives) : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall (proportion of true positives that were actually correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:34.659301Z",
     "iopub.status.busy": "2020-05-27T23:33:34.658872Z",
     "iopub.status.idle": "2020-05-27T23:33:35.361779Z",
     "shell.execute_reply": "2020-05-27T23:33:35.360386Z",
     "shell.execute_reply.started": "2020-05-27T23:33:34.659257Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionRecall(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositives = truePositivePredictions(predictions: predictions, samples: samples)\n",
    "    let actualPositivePredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        switch outputs {\n",
    "        case (1, 1), (0, 1):\n",
    "            checked.append(1)\n",
    "        default:\n",
    "            checked.append(0)\n",
    "        }\n",
    "    }\n",
    "    let actualPositives = actualPositivePredictions.reduce(0, +)\n",
    "    return truePositives / actualPositives\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F₁ measure (harmonic mean of precision and recall) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:35.363253Z",
     "iopub.status.busy": "2020-05-27T23:33:35.362949Z",
     "iopub.status.idle": "2020-05-27T23:33:35.590305Z",
     "shell.execute_reply": "2020-05-27T23:33:35.585587Z",
     "shell.execute_reply.started": "2020-05-27T23:33:35.363223Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionF1(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let precision = predictionPrecision(predictions: predictions, samples: samples)\n",
    "    let recall = predictionRecall(predictions: predictions, samples: samples)\n",
    "    return 2 / ((1 / recall) + (1 / precision))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is the truth table for $A \\lor B$, structured as an array of tuples $[(\\mathbf{x}_j, d_j)] = [((\\mathbf{x}_{j, 1}, \\mathbf{x}_{j, 2}, \\mathbf{x}_{j, 3}), d_j)]$ where:\n",
    "\n",
    "- $\\mathbf{x}_j$ is the input\n",
    "- $\\mathbf{x}_{j, 0} = 1$ (to act as a bias value, in concert with $w_0$)\n",
    "- $d_j$ is the correct, sampled output value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:35.592204Z",
     "iopub.status.busy": "2020-05-27T23:33:35.591809Z",
     "iopub.status.idle": "2020-05-27T23:33:36.335220Z",
     "shell.execute_reply": "2020-05-27T23:33:36.333511Z",
     "shell.execute_reply.started": "2020-05-27T23:33:35.592177Z"
    }
   },
   "outputs": [],
   "source": [
    "let orTrainingSet: [([Double], Double)] = [\n",
    "    ([1, 0, 0], 0),\n",
    "    ([1, 0, 1], 1),\n",
    "    ([1, 1, 0], 1),\n",
    "    ([1, 1, 1], 1)\n",
    "]\n",
    "let orTrainingSetInputs: [[Double]] = orTrainingSet.map { $0.0 }\n",
    "let orTrainingSetOutputs: [Double] = orTrainingSet.map { $0.1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an untrained Perceptron with an initial set of weights $\\mathbf{w} = (0, 0, 0)$, calculate the predicted outputs for the training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:36.337515Z",
     "iopub.status.busy": "2020-05-27T23:33:36.336921Z",
     "iopub.status.idle": "2020-05-27T23:33:36.832126Z",
     "shell.execute_reply": "2020-05-27T23:33:36.822100Z",
     "shell.execute_reply.started": "2020-05-27T23:33:36.337348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ 4 elements\n",
       "  - 0 : 0.0\n",
       "  - 1 : 0.0\n",
       "  - 2 : 0.0\n",
       "  - 3 : 0.0\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedOutputs(orTrainingSetInputs, weights: [0, 0, 0], activation: unitStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean error for the untrained Perceptron on the training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:36.834086Z",
     "iopub.status.busy": "2020-05-27T23:33:36.833653Z",
     "iopub.status.idle": "2020-05-27T23:33:37.399317Z",
     "shell.execute_reply": "2020-05-27T23:33:37.389378Z",
     "shell.execute_reply.started": "2020-05-27T23:33:36.834047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanError(\n",
    "    predictions: predictedOutputs(orTrainingSetInputs, weights: [0, 0, 0], activation: unitStep),\n",
    "    samples: orTrainingSetOutputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the weights during Perceptron training, modify each weight $w_i$ by adding $r E(x_j) x_{j,i}$ to it, where $r \\in [0, 1]$ is the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:37.400825Z",
     "iopub.status.busy": "2020-05-27T23:33:37.400589Z",
     "iopub.status.idle": "2020-05-27T23:33:38.295071Z",
     "shell.execute_reply": "2020-05-27T23:33:38.293539Z",
     "shell.execute_reply.started": "2020-05-27T23:33:37.400797Z"
    }
   },
   "outputs": [],
   "source": [
    "func updatedWeights(_ oldWeights: [Double], error: Double, inputs: [Double], learningRate: Double) -> [Double] {\n",
    "    let weightsDelta = learningRate * error\n",
    "    let newWeights = oldWeights.enumerated().map { $1 + (weightsDelta * inputs[$0]) }\n",
    "    return newWeights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the Perceptron, calculate the predicted output $\\hat{y}_j$ based on the current weights $\\mathbf{w}$ and the activation function $\\phi$, then update the weights based on the error $E(\\mathbf{x}_j)$. Repeat until $E(\\mathbf{x}_j) < \\gamma$, where $\\gamma$ is the error threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:38.297236Z",
     "iopub.status.busy": "2020-05-27T23:33:38.296804Z",
     "iopub.status.idle": "2020-05-27T23:33:41.007288Z",
     "shell.execute_reply": "2020-05-27T23:33:41.006027Z",
     "shell.execute_reply.started": "2020-05-27T23:33:38.297192Z"
    }
   },
   "outputs": [],
   "source": [
    "func trainWeights(\n",
    "    startingFrom startingWeights: [Double],\n",
    "    samples: [([Double], Double)],\n",
    "    learningRate: Double = 0.1,\n",
    "    errorThreshold: Double = 0.25,\n",
    "    maximumIterationCount: Int = Int(1e4),\n",
    "    activation: (Double) -> (Double)\n",
    ") -> [Double]\n",
    "{\n",
    "    let sampledInputs = samples.map { $0.0 }\n",
    "    let sampledOutputs = samples.map { $0.1 }\n",
    "    let shuffledSamples = samples.shuffled()\n",
    "    let sampleCount = samples.count\n",
    "    let printMeanErrorIterationCount = maximumIterationCount / 10\n",
    "    var currentWeights = startingWeights\n",
    "    var predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "    var averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "    var accuracy = predictionAccuracy(predictions: predictions, samples: sampledOutputs)\n",
    "    var precision = predictionPrecision(predictions: predictions, samples: sampledOutputs)\n",
    "    var recall = predictionRecall(predictions: predictions, samples: sampledOutputs)\n",
    "    var f1 = predictionF1(predictions: predictions, samples: sampledOutputs)\n",
    "    var iterations = 0\n",
    "\n",
    "    print(\"Starting weights:\", startingWeights)\n",
    "    print(\"Predicted outputs:\", predictions)\n",
    "    print(\"Mean error:\", averageError)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "    print(\"\")\n",
    "\n",
    "    while averageError >= errorThreshold {\n",
    "        if iterations >= maximumIterationCount { break }\n",
    "        if iterations % printMeanErrorIterationCount == 0 { print(\"Mean error:\", averageError) }\n",
    "        iterations += 1\n",
    "\n",
    "        let (currentInputs, currentOutput) = shuffledSamples[iterations % sampleCount]\n",
    "        let predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "        averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "        let prediction = predictedOutput(currentInputs, weights: currentWeights, activation: activation)\n",
    "        let currentError = error(prediction: prediction, sample: currentOutput)\n",
    "        currentWeights = updatedWeights(currentWeights, error: currentError, inputs: currentInputs, learningRate: learningRate)\n",
    "    }\n",
    "\n",
    "    predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "    averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "    accuracy = predictionAccuracy(predictions: predictions, samples: sampledOutputs)\n",
    "    precision = predictionPrecision(predictions: predictions, samples: sampledOutputs)\n",
    "    recall = predictionRecall(predictions: predictions, samples: sampledOutputs)\n",
    "    f1 = predictionF1(predictions: predictions, samples: sampledOutputs)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Epochs:\", iterations / sampleCount)\n",
    "    print(\"Iterations:\", iterations)\n",
    "    print(\"Final weights:\", currentWeights)\n",
    "    print(\"Predicted outputs:\", predictions)\n",
    "    print(\"Mean error:\", averageError)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "\n",
    "    return currentWeights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Perceptron to perform inclusive disjunction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:33:41.010105Z",
     "iopub.status.busy": "2020-05-27T23:33:41.009677Z",
     "iopub.status.idle": "2020-05-27T23:33:41.785517Z",
     "shell.execute_reply": "2020-05-27T23:33:41.780484Z",
     "shell.execute_reply.started": "2020-05-27T23:33:41.010067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights: [0.0, 0.0, 0.0]\n",
      "Predicted outputs: [0.0, 0.0, 0.0, 0.0]\n",
      "Mean error: 0.75\n",
      "Accuracy: 0.25\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "\n",
      "Mean error: 0.75\n",
      "\n",
      "Epochs: 1\n",
      "Iterations: 7\n",
      "Final weights: [0.0, 0.1, 0.1]\n",
      "Predicted outputs: [0.0, 1.0, 1.0, 1.0]\n",
      "Mean error: 0.0\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "▿ 3 elements\n",
       "  - 0 : 0.0\n",
       "  - 1 : 0.1\n",
       "  - 2 : 0.1\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWeights(\n",
    "    startingFrom: [0, 0, 0],\n",
    "    samples: orTrainingSet,\n",
    "    learningRate: 0.1,\n",
    "    errorThreshold: 0.25,\n",
    "    activation: unitStep\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  },
  "output_auto_scroll": true,
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

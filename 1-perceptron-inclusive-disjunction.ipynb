{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training a Perceptron to perform inclusive disjunction using plain Swift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Christopher Boone](https://github.com/cboone)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/cboone/swift-neural-intuition/blob/master/1-perceptron-inclusive-disjunction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Following [Wikipedia's summary of the Perceptron learning algorithm](https://en.m.wikipedia.org/wiki/Perceptron#Learning_algorithm). Using Arrays to represent vectors and Doubles for all numbers, for simplicity._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network takes features as input vector $\\mathbf{x}_j$, a vector of weights (one per feature) as $\\mathbf{w}$, and an activation function $\\phi$, where $x_{j,i}, w_{i}, \\hat{y}_j \\in \\{0, 1\\}$ and $x_{j,0} = 1$:\n",
    "\n",
    "$$\\hat{y}_j = \\phi(\\mathbf{w} \\cdot \\mathbf{x}_j)$$\n",
    "\n",
    "Training the Perceptron requires: \n",
    "- a learning rate $r \\in [0, 1]$\n",
    "- a training set of sampled data $D = \\{(\\mathbf{x}_1, d_1), \\dots, (\\mathbf{x}_m, d_m)\\}$, where $\\mathbf{x}_j$ is the $n$-dimensional input vector, $d_j$ is the sampled (expected) output, and $m$ is the number of samples\n",
    "- an initial set of weights\n",
    "- an error threshold $\\gamma \\in [0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product of two vectors is defined by $\\mathbf{a} \\cdot \\mathbf{b} = \\sum _{i=1}^{n} a_{i} b_{i}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:28:54.357735Z",
     "iopub.status.busy": "2020-05-27T23:28:54.357057Z",
     "iopub.status.idle": "2020-05-27T23:28:59.797623Z",
     "shell.execute_reply": "2020-05-27T23:28:59.796727Z",
     "shell.execute_reply.started": "2020-05-27T23:28:54.357602Z"
    }
   },
   "outputs": [],
   "source": [
    "func dotProduct(_ a: [Double], _ b: [Double]) -> Double {\n",
    "    zip(a, b).map(*).reduce(0, +)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function is the Heaviside or unit step function, which can be defined by $H(x) = \\frac{x + \\left|x\\right|}{2x}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:28:59.799785Z",
     "iopub.status.busy": "2020-05-27T23:28:59.799095Z",
     "iopub.status.idle": "2020-05-27T23:29:00.437085Z",
     "shell.execute_reply": "2020-05-27T23:29:00.436066Z",
     "shell.execute_reply.started": "2020-05-27T23:28:59.799745Z"
    }
   },
   "outputs": [],
   "source": [
    "func unitStep(_ x: Double) -> Double {\n",
    "    (x > 0) ? 1 : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted output of the Perceptron can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:00.438960Z",
     "iopub.status.busy": "2020-05-27T23:29:00.438577Z",
     "iopub.status.idle": "2020-05-27T23:29:00.626674Z",
     "shell.execute_reply": "2020-05-27T23:29:00.625716Z",
     "shell.execute_reply.started": "2020-05-27T23:29:00.438931Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictedOutput(_ inputs: [Double], weights: [Double], activation: (Double) -> (Double)) -> Double {\n",
    "    activation(dotProduct(weights, inputs))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, given an array of input values, by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:00.630440Z",
     "iopub.status.busy": "2020-05-27T23:29:00.629591Z",
     "iopub.status.idle": "2020-05-27T23:29:01.116558Z",
     "shell.execute_reply": "2020-05-27T23:29:01.114582Z",
     "shell.execute_reply.started": "2020-05-27T23:29:00.630406Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictedOutputs(_ inputs: [[Double]], weights: [Double], activation: (Double) -> (Double)) -> [Double] {\n",
    "    inputs.map { predictedOutput($0, weights: weights, activation: activation) }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Perceptron's error function (or cost function, objective function, loss function) is defined by $E(\\mathbf{x}_j) = y_j - \\hat{y}_j$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:01.120267Z",
     "iopub.status.busy": "2020-05-27T23:29:01.119261Z",
     "iopub.status.idle": "2020-05-27T23:29:01.301682Z",
     "shell.execute_reply": "2020-05-27T23:29:01.300011Z",
     "shell.execute_reply.started": "2020-05-27T23:29:01.120033Z"
    }
   },
   "outputs": [],
   "source": [
    "func error(prediction: Double, sample: Double) -> Double {\n",
    "    sample - prediction\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean error is given by $\\frac{1}{m} \\sum_{j=1}^{m} \\lvert y_j - \\hat{y}_j \\rvert$, where $m$ is the number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:01.304692Z",
     "iopub.status.busy": "2020-05-27T23:29:01.303036Z",
     "iopub.status.idle": "2020-05-27T23:29:02.405909Z",
     "shell.execute_reply": "2020-05-27T23:29:02.404691Z",
     "shell.execute_reply.started": "2020-05-27T23:29:01.304637Z"
    }
   },
   "outputs": [],
   "source": [
    "func meanError(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let summedError = zip(samples, predictions).map(error).map(abs).reduce(0, +)\n",
    "    return (1 / Double(samples.count)) * summedError\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy (percentage correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:02.413981Z",
     "iopub.status.busy": "2020-05-27T23:29:02.412573Z",
     "iopub.status.idle": "2020-05-27T23:29:03.708380Z",
     "shell.execute_reply": "2020-05-27T23:29:03.707363Z",
     "shell.execute_reply.started": "2020-05-27T23:29:02.413929Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionAccuracy(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let checkedPredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        checked.append(outputs.0 == outputs.1 ? 1 : 0)\n",
    "    }\n",
    "    let correct = checkedPredictions.reduce(0, +)\n",
    "    return correct / Double(predictions.count)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of true positive predictions can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:03.711927Z",
     "iopub.status.busy": "2020-05-27T23:29:03.711563Z",
     "iopub.status.idle": "2020-05-27T23:29:04.348551Z",
     "shell.execute_reply": "2020-05-27T23:29:04.347654Z",
     "shell.execute_reply.started": "2020-05-27T23:29:03.711883Z"
    }
   },
   "outputs": [],
   "source": [
    "func truePositivePredictions(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositivePredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        outputs == (1, 1) ? checked.append(1) : checked.append(0)\n",
    "    }\n",
    "    return truePositivePredictions.reduce(0, +)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision (proportion of positive identifications that were actually correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:04.361097Z",
     "iopub.status.busy": "2020-05-27T23:29:04.357645Z",
     "iopub.status.idle": "2020-05-27T23:29:05.247510Z",
     "shell.execute_reply": "2020-05-27T23:29:05.244920Z",
     "shell.execute_reply.started": "2020-05-27T23:29:04.361034Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionPrecision(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositives = truePositivePredictions(predictions: predictions, samples: samples)\n",
    "    let allPositives = predictions.reduce(0, +)\n",
    "    return (allPositives > 0) ? (truePositives / allPositives) : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall (proportion of true positives that were actually correct) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:05.256816Z",
     "iopub.status.busy": "2020-05-27T23:29:05.256250Z",
     "iopub.status.idle": "2020-05-27T23:29:05.925225Z",
     "shell.execute_reply": "2020-05-27T23:29:05.924229Z",
     "shell.execute_reply.started": "2020-05-27T23:29:05.256776Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionRecall(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let truePositives = truePositivePredictions(predictions: predictions, samples: samples)\n",
    "    let actualPositivePredictions = zip(predictions, samples).reduce(into: [Double]()) { checked, outputs in\n",
    "        switch outputs {\n",
    "        case (1, 1), (0, 1):\n",
    "            checked.append(1)\n",
    "        default:\n",
    "            checked.append(0)\n",
    "        }\n",
    "    }\n",
    "    let actualPositives = actualPositivePredictions.reduce(0, +)\n",
    "    return truePositives / actualPositives\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F₁ measure (harmonic mean of precision and recall) can be calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:05.935504Z",
     "iopub.status.busy": "2020-05-27T23:29:05.932415Z",
     "iopub.status.idle": "2020-05-27T23:29:06.229694Z",
     "shell.execute_reply": "2020-05-27T23:29:06.228415Z",
     "shell.execute_reply.started": "2020-05-27T23:29:05.935446Z"
    }
   },
   "outputs": [],
   "source": [
    "func predictionF1(predictions: [Double], samples: [Double]) -> Double {\n",
    "    let precision = predictionPrecision(predictions: predictions, samples: samples)\n",
    "    let recall = predictionRecall(predictions: predictions, samples: samples)\n",
    "    return 2 / ((1 / recall) + (1 / precision))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is the truth table for $A \\lor B$, structured as an array of tuples $[(\\mathbf{x}_j, d_j)] = [((\\mathbf{x}_{j, 1}, \\mathbf{x}_{j, 2}, \\mathbf{x}_{j, 3}), d_j)]$ where:\n",
    "\n",
    "- $\\mathbf{x}_j$ is the input\n",
    "- $\\mathbf{x}_{j, 0} = 1$ (to act as a bias value, in concert with $w_0$)\n",
    "- $d_j$ is the correct, sampled output value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:06.231604Z",
     "iopub.status.busy": "2020-05-27T23:29:06.231146Z",
     "iopub.status.idle": "2020-05-27T23:29:07.380592Z",
     "shell.execute_reply": "2020-05-27T23:29:07.379195Z",
     "shell.execute_reply.started": "2020-05-27T23:29:06.231546Z"
    }
   },
   "outputs": [],
   "source": [
    "let orTrainingSet: [([Double], Double)] = [\n",
    "    ([1, 0, 0], 0),\n",
    "    ([1, 0, 1], 1),\n",
    "    ([1, 1, 0], 1),\n",
    "    ([1, 1, 1], 1)\n",
    "]\n",
    "let orTrainingSetInputs: [[Double]] = orTrainingSet.map { $0.0 }\n",
    "let orTrainingSetOutputs: [Double] = orTrainingSet.map { $0.1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an untrained Perceptron with an initial set of weights $\\mathbf{w} = (0, 0, 0)$, calculate the predicted outputs for the training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:07.385518Z",
     "iopub.status.busy": "2020-05-27T23:29:07.385113Z",
     "iopub.status.idle": "2020-05-27T23:29:08.045810Z",
     "shell.execute_reply": "2020-05-27T23:29:08.041934Z",
     "shell.execute_reply.started": "2020-05-27T23:29:07.385479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ 4 elements\n",
       "  - 0 : 0.0\n",
       "  - 1 : 0.0\n",
       "  - 2 : 0.0\n",
       "  - 3 : 0.0\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedOutputs(orTrainingSetInputs, weights: [0, 0, 0], activation: unitStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean error for the untrained Perceptron on the training inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:08.063774Z",
     "iopub.status.busy": "2020-05-27T23:29:08.063428Z",
     "iopub.status.idle": "2020-05-27T23:29:08.812881Z",
     "shell.execute_reply": "2020-05-27T23:29:08.808692Z",
     "shell.execute_reply.started": "2020-05-27T23:29:08.063736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanError(\n",
    "    predictions: predictedOutputs(orTrainingSetInputs, weights: [0, 0, 0], activation: unitStep),\n",
    "    samples: orTrainingSetOutputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the weights during Perceptron training, modify each weight $w_i$ by adding $r E(x_j) x_{j,i}$ to it, where $r \\in [0, 1]$ is the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:08.822905Z",
     "iopub.status.busy": "2020-05-27T23:29:08.815892Z",
     "iopub.status.idle": "2020-05-27T23:29:10.240575Z",
     "shell.execute_reply": "2020-05-27T23:29:10.239064Z",
     "shell.execute_reply.started": "2020-05-27T23:29:08.822855Z"
    }
   },
   "outputs": [],
   "source": [
    "func updatedWeights(_ oldWeights: [Double], error: Double, inputs: [Double], learningRate: Double) -> [Double] {\n",
    "    let weightsDelta = learningRate * error\n",
    "    let newWeights = oldWeights.enumerated().map { $1 + (weightsDelta * inputs[$0]) }\n",
    "    return newWeights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the Perceptron, calculate the predicted output $\\hat{y}_j$ based on the current weights $\\mathbf{w}$ and the activation function $\\phi$, then update the weights based on the error $E(\\mathbf{x}_j)$. Repeat until $E(\\mathbf{x}_j) < \\gamma$, where $\\gamma$ is the error threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:10.242761Z",
     "iopub.status.busy": "2020-05-27T23:29:10.241881Z",
     "iopub.status.idle": "2020-05-27T23:29:13.135532Z",
     "shell.execute_reply": "2020-05-27T23:29:13.134404Z",
     "shell.execute_reply.started": "2020-05-27T23:29:10.242719Z"
    }
   },
   "outputs": [],
   "source": [
    "func trainWeights(\n",
    "    startingFrom startingWeights: [Double],\n",
    "    samples: [([Double], Double)],\n",
    "    learningRate: Double = 0.1,\n",
    "    errorThreshold: Double = 0.25,\n",
    "    maximumIterationCount: Int = Int(1e4),\n",
    "    activation: (Double) -> (Double)\n",
    ") -> [Double]\n",
    "{\n",
    "    let sampledInputs = samples.map { $0.0 }\n",
    "    let sampledOutputs = samples.map { $0.1 }\n",
    "    let shuffledSamples = samples.shuffled()\n",
    "    let sampleCount = samples.count\n",
    "    let printMeanErrorIterationCount = Int(1e3)\n",
    "    var currentWeights = startingWeights\n",
    "    var predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "    var averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "    var accuracy = predictionAccuracy(predictions: predictions, samples: sampledOutputs)\n",
    "    var precision = predictionPrecision(predictions: predictions, samples: sampledOutputs)\n",
    "    var recall = predictionRecall(predictions: predictions, samples: sampledOutputs)\n",
    "    var f1 = predictionF1(predictions: predictions, samples: sampledOutputs)\n",
    "    var iterations = 0\n",
    "\n",
    "    print(\"Starting weights:\", startingWeights)\n",
    "    print(\"Predicted outputs:\", predictions)\n",
    "    print(\"Mean error:\", averageError)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "    print(\"\")\n",
    "\n",
    "    while averageError >= errorThreshold {\n",
    "        if iterations >= maximumIterationCount { break }\n",
    "        if iterations % printMeanErrorIterationCount == 0 { print(\"Mean error:\", averageError) }\n",
    "        iterations += 1\n",
    "\n",
    "        let (currentInputs, currentOutput) = shuffledSamples[iterations % sampleCount]\n",
    "        let predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "        averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "        let prediction = predictedOutput(currentInputs, weights: currentWeights, activation: activation)\n",
    "        let currentError = error(prediction: prediction, sample: currentOutput)\n",
    "        currentWeights = updatedWeights(currentWeights, error: currentError, inputs: currentInputs, learningRate: learningRate)\n",
    "    }\n",
    "\n",
    "    predictions = predictedOutputs(sampledInputs, weights: currentWeights, activation: activation)\n",
    "    averageError = meanError(predictions: predictions, samples: sampledOutputs)\n",
    "    accuracy = predictionAccuracy(predictions: predictions, samples: sampledOutputs)\n",
    "    precision = predictionPrecision(predictions: predictions, samples: sampledOutputs)\n",
    "    recall = predictionRecall(predictions: predictions, samples: sampledOutputs)\n",
    "    f1 = predictionF1(predictions: predictions, samples: sampledOutputs)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Epochs:\", iterations / sampleCount)\n",
    "    print(\"Iterations:\", iterations)\n",
    "    print(\"Final weights:\", currentWeights)\n",
    "    print(\"Predicted outputs:\", predictions)\n",
    "    print(\"Mean error:\", averageError)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "\n",
    "    return currentWeights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Perceptron to perform inclusive disjunction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-27T23:29:13.139064Z",
     "iopub.status.busy": "2020-05-27T23:29:13.138310Z",
     "iopub.status.idle": "2020-05-27T23:29:13.589857Z",
     "shell.execute_reply": "2020-05-27T23:29:13.588698Z",
     "shell.execute_reply.started": "2020-05-27T23:29:13.139021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights: [0.0, 0.0, 0.0]\n",
      "Predicted outputs: [0.0, 0.0, 0.0, 0.0]\n",
      "Mean error: 0.75\n",
      "Accuracy: 0.25\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "\n",
      "Mean error: 0.75\n",
      "\n",
      "Epochs: 2\n",
      "Iterations: 9\n",
      "Final weights: [0.0, 0.1, 0.1]\n",
      "Predicted outputs: [0.0, 1.0, 1.0, 1.0]\n",
      "Mean error: 0.0\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "▿ 3 elements\n",
       "  - 0 : 0.0\n",
       "  - 1 : 0.1\n",
       "  - 2 : 0.1\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWeights(\n",
    "    startingFrom: [0, 0, 0],\n",
    "    samples: orTrainingSet,\n",
    "    learningRate: 0.1,\n",
    "    errorThreshold: 0.25,\n",
    "    activation: unitStep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  },
  "output_auto_scroll": true,
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
